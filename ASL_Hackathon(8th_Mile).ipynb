{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skriller18/JungliFungli/blob/main/ASL_Hackathon(8th_Mile).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "pgkZB3-zfALk",
        "outputId": "73054df4-5ac5-45f6-c64a-a16559462ce3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'import os\\nimport random\\nimport shutil\\nimport string\\n\\ndef split_dataset(input_dir, split_ratio):\\n    os.makedirs(train_dir, exist_ok=True)\\n    os.makedirs(test_dir, exist_ok=True)\\n\\n    for filename in os.listdir(input_dir):\\n        filepath = os.path.join(input_dir, filename)\\n        if random.random() < split_ratio:\\n            shutil.copy(filepath, os.path.join(train_dir, filename))\\n        else:\\n            shutil.copy(filepath, os.path.join(test_dir, filename))'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Splitting into test and train dataset\n",
        "\n",
        "'''import os\n",
        "import random\n",
        "import shutil\n",
        "import string\n",
        "\n",
        "def split_dataset(input_dir, split_ratio):\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(input_dir):\n",
        "        filepath = os.path.join(input_dir, filename)\n",
        "        if random.random() < split_ratio:\n",
        "            shutil.copy(filepath, os.path.join(train_dir, filename))\n",
        "        else:\n",
        "            shutil.copy(filepath, os.path.join(test_dir, filename))'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "kEOcF4z2gNSH",
        "outputId": "9d5efddb-6083-4b1d-e4f1-aaf674880a12"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'input = \"/content/drive/MyDrive/asl_dataset/\"\\noutput = \"/content/drive/MyDrive/Sign_Dataset\"\\nfor char in string.ascii_lowercase:\\n  input1 = os.path.join(input,char)\\n  train = \"/Train/\"+char\\n  test = \"/Test/\"+char\\n  train_dir = os.path.join(output,train)\\n  test_dir = os.path.join(output,test)\\n  split_dataset(input1,0.8)'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''input = \"/content/drive/MyDrive/asl_dataset/\"\n",
        "output = \"/content/drive/MyDrive/Sign_Dataset\"\n",
        "for char in string.ascii_lowercase:\n",
        "  input1 = os.path.join(input,char)\n",
        "  train = \"/Train/\"+char\n",
        "  test = \"/Test/\"+char\n",
        "  train_dir = os.path.join(output,train)\n",
        "  test_dir = os.path.join(output,test)\n",
        "  split_dataset(input1,0.8)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG0G8db_jxYX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnEYtJmMl_sT",
        "outputId": "93ca8b72-921c-466d-9e3e-56b59aab4255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-06-15 18:04:13--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-15 18:04:13 (75.4 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQJiJUcMmCex"
      },
      "outputs": [],
      "source": [
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXzIO-3ImIrM",
        "outputId": "edd47ab1-6d02-4f69-a1f2-9c7e3fa25f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 2 directories and 0 images in '/content/drive/MyDrive/Sign_Dataset'.\n",
            "There are 26 directories and 0 images in '/content/drive/MyDrive/Sign_Dataset/Test'.\n",
            "There are 0 directories and 46 images in '/content/drive/MyDrive/Sign_Dataset/Test/b'.\n",
            "There are 0 directories and 50 images in '/content/drive/MyDrive/Sign_Dataset/Test/a'.\n",
            "There are 0 directories and 39 images in '/content/drive/MyDrive/Sign_Dataset/Test/c'.\n",
            "There are 0 directories and 53 images in '/content/drive/MyDrive/Sign_Dataset/Test/e'.\n",
            "There are 0 directories and 52 images in '/content/drive/MyDrive/Sign_Dataset/Test/f'.\n",
            "There are 0 directories and 44 images in '/content/drive/MyDrive/Sign_Dataset/Test/j'.\n",
            "There are 0 directories and 46 images in '/content/drive/MyDrive/Sign_Dataset/Test/d'.\n",
            "There are 0 directories and 44 images in '/content/drive/MyDrive/Sign_Dataset/Test/i'.\n",
            "There are 0 directories and 42 images in '/content/drive/MyDrive/Sign_Dataset/Test/h'.\n",
            "There are 0 directories and 45 images in '/content/drive/MyDrive/Sign_Dataset/Test/g'.\n",
            "There are 0 directories and 44 images in '/content/drive/MyDrive/Sign_Dataset/Test/p'.\n",
            "There are 0 directories and 49 images in '/content/drive/MyDrive/Sign_Dataset/Test/q'.\n",
            "There are 0 directories and 43 images in '/content/drive/MyDrive/Sign_Dataset/Test/n'.\n",
            "There are 0 directories and 44 images in '/content/drive/MyDrive/Sign_Dataset/Test/o'.\n",
            "There are 0 directories and 45 images in '/content/drive/MyDrive/Sign_Dataset/Test/l'.\n",
            "There are 0 directories and 47 images in '/content/drive/MyDrive/Sign_Dataset/Test/m'.\n",
            "There are 0 directories and 46 images in '/content/drive/MyDrive/Sign_Dataset/Test/k'.\n",
            "There are 0 directories and 50 images in '/content/drive/MyDrive/Sign_Dataset/Test/u'.\n",
            "There are 0 directories and 48 images in '/content/drive/MyDrive/Sign_Dataset/Test/w'.\n",
            "There are 0 directories and 46 images in '/content/drive/MyDrive/Sign_Dataset/Test/x'.\n",
            "There are 0 directories and 50 images in '/content/drive/MyDrive/Sign_Dataset/Test/v'.\n",
            "There are 0 directories and 48 images in '/content/drive/MyDrive/Sign_Dataset/Test/s'.\n",
            "There are 0 directories and 42 images in '/content/drive/MyDrive/Sign_Dataset/Test/t'.\n",
            "There are 0 directories and 44 images in '/content/drive/MyDrive/Sign_Dataset/Test/r'.\n",
            "There are 0 directories and 45 images in '/content/drive/MyDrive/Sign_Dataset/Test/y'.\n",
            "There are 0 directories and 46 images in '/content/drive/MyDrive/Sign_Dataset/Test/z'.\n",
            "There are 26 directories and 0 images in '/content/drive/MyDrive/Sign_Dataset/Train'.\n",
            "There are 0 directories and 65 images in '/content/drive/MyDrive/Sign_Dataset/Train/t'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/f'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/e'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/c'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/g'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/h'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/l'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/j'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/o'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/q'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/r'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/u'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/y'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/d'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/a'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/b'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/k'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/i'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/n'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/m'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/s'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/w'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/v'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/z'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/p'.\n",
            "There are 0 directories and 70 images in '/content/drive/MyDrive/Sign_Dataset/Train/x'.\n"
          ]
        }
      ],
      "source": [
        "walk_through_dir(\"/content/drive/MyDrive/Sign_Dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3h_CRTkk7Sx"
      },
      "outputs": [],
      "source": [
        "test_dir = \"/content/drive/MyDrive/Sign_Dataset/Test\"\n",
        "train_dir = \"/content/drive/MyDrive/Sign_Dataset/Train\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_USnQcplaq6",
        "outputId": "ed3e6b81-6232-443a-8ac5-6550af8f4551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1815 files belonging to 26 classes.\n",
            "Found 1198 files belonging to 26 classes.\n"
          ]
        }
      ],
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(directory = train_dir,\n",
        "                                                                  image_size = IMG_SIZE,\n",
        "                                                                  label_mode = \"categorical\",\n",
        "                                                                  batch_size = BATCH_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory = test_dir,\n",
        "                                                                image_size = IMG_SIZE,\n",
        "                                                                label_mode = \"categorical\",\n",
        "                                                                batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUObXnsYhkKR",
        "outputId": "094b91c7-e297-40ce-d142-46c1c224e922"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after GLOBALAVERAGEPOOLING: (None, 1280)\n",
            "Saving TensorBoard log files to: Sign_dataset/ASL-Dataset/20230615-180431\n",
            "Epoch 1/5\n",
            "57/57 [==============================] - 241s 4s/step - loss: 2.6611 - accuracy: 0.3620 - val_loss: 1.9377 - val_accuracy: 0.7847\n",
            "Epoch 2/5\n"
          ]
        }
      ],
      "source": [
        "#Creating the base model with tf.keras.functional API\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "#Freeze the base model\n",
        "base_model.trainable=False\n",
        "\n",
        "#Create inputs into the model\n",
        "inputs = tf.keras.layers.Input(shape = (224,224,3), name = \"Input_Layer\")\n",
        "\n",
        "#Normalising(incase for Resnet)\n",
        "#normal = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "#Pass the inputs to the base model\n",
        "x = base_model(inputs)\n",
        "\n",
        "#Average pool the outputs\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"golbal_pooling_layer\")(x)\n",
        "print(f\"Shape after GLOBALAVERAGEPOOLING: {x.shape}\")\n",
        "\n",
        "#Create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(26,activation=\"softmax\",name=\"output_layer\")(x)\n",
        "\n",
        "#Combine inputs and outputs\n",
        "model_0 = tf.keras.Model(inputs,outputs)\n",
        "\n",
        "#Compile the model\n",
        "model_0.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "#Fit the model\n",
        "history_0 = model_0.fit(train_data,\n",
        "                        epochs = 5,\n",
        "                        steps_per_epoch = len(train_data),\n",
        "                        validation_data = test_data,\n",
        "                        validation_steps = int(0.25*len(test_data)),\n",
        "                        callbacks = [create_tensorboard_callback(dir_name = \"Sign_dataset\",\n",
        "                                                                 experiment_name=\"ASL-Dataset\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry95f14_oDdb"
      },
      "outputs": [],
      "source": [
        "model_0.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HipT-OwaoYdV"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gjn-sSN5ovGi"
      },
      "outputs": [],
      "source": [
        "model_0.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdacFynUo4r8"
      },
      "outputs": [],
      "source": [
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEG3P1h1qgXe"
      },
      "outputs": [],
      "source": [
        "'''Y_probs = multimod.predict(test_data)\n",
        "print(Y_probs)\n",
        "\n",
        "Y_preds = Y_probs.argmax(axis=1)\n",
        "print(Y_preds)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnK3Y3KNo-wj"
      },
      "outputs": [],
      "source": [
        "'''#Plotting our predictions in a confusion matrix\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "figsize = (10, 10)\n",
        "\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15):\n",
        "#Create the confusion matrix\n",
        "  cm = confusion_matrix(y_true, tf.round(y_pred))\n",
        "  cm_norm = cm.astype(\"float\")/ cm.sum(axis=1)[:,np.newaxis]\n",
        "  n_classes = cm.shape[0]\n",
        "\n",
        "  #Subplotting each class and associating it with each other\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "\n",
        "  #Create a matrix plot\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  #Set class labels\n",
        "  if classes:\n",
        "    labels=classes\n",
        "  else:\n",
        "    labels=np.arange(cm.shape[0])\n",
        "\n",
        "  #Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "        xlabel=\"Predicted Label\",\n",
        "        ylabel=\"True Label\",\n",
        "        xticks=np.arange(n_classes),\n",
        "        yticks=np.arange(n_classes),\n",
        "        xticklabels=labels,\n",
        "        yticklabels=labels)\n",
        "\n",
        "  #Set threshold for different colors\n",
        "  threshold = (cm.max()+ cm.min())/2\n",
        "\n",
        "  #Plot text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[0])):\n",
        "    plt.text(j, i, f\"{cm[i,j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "            size=15)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXFT_t1VrIbR"
      },
      "outputs": [],
      "source": [
        "#Create a function to import an image and resize it to able to use it for the model and predict results\n",
        "\n",
        "def load_and_prep_img(filename, img_shape=24):\n",
        "  #Read the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  #Decode the read file into a tensor\n",
        "  img = tf.image.decode_image(img)\n",
        "  #Resize our image\n",
        "  img = tf.image.resize(img, size={img_shape, img_shape})\n",
        "  #Normalising the image\n",
        "  img = img/255\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KALOAa6vwZqd"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W1OVNK_wZqe"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "\n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5wunvV2z9fD"
      },
      "outputs": [],
      "source": [
        "def load_and_prep_image(filename, img_shape=224):\n",
        "  # Read in target file (an image)\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  # Decode the read file into a tensor & ensure 3 colour channels\n",
        "  # (our model is trained on images with 3 colour channels and sometimes images have 4 colour channels)\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "\n",
        "  # Resize the image (to the same size our model was trained on)\n",
        "  img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  img = img/255\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxBN-5Qi0EFZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  pred_array = np.array(pred)\n",
        "  pred_class = class_names[np.argmax(pred_array)]\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xOkpFxO0H5z"
      },
      "outputs": [],
      "source": [
        "class_names = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efRIOwhk0l-r"
      },
      "outputs": [],
      "source": [
        "pred_and_plot(model_0,\"/content/drive/MyDrive/p.jpg\", class_names)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1J93TOmIcjc0hVtTna-mIvD_ZjB4nbN6Y",
      "authorship_tag": "ABX9TyO3hugVvvykd2YFLKnC8x0n",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}